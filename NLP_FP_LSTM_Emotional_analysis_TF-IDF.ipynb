{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP FP LSTM Emotional analysis .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4Owv8Rzx7EdAKAdBPS8uO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gamecicn/Deep-Learning-Papers-Reading-Roadmap/blob/master/NLP_FP_LSTM_Emotional_analysis_TF-IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asDAvqkwj4hV"
      },
      "source": [
        "# NLP FP Emotional analysis"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAebpWgwkWCi",
        "outputId": "3710866d-d13e-487c-9ef8-2e8c08ca8be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "# Install\n",
        "!pip install numpy==1.16.2\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 1.5MB/s \n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyRfktHBkPPE"
      },
      "source": [
        "# Setup\n",
        "\n",
        "\n",
        "\n",
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "\n",
        " \n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIKaXvVQk3br",
        "outputId": "9eff8c82-1545-45de-ddf3-3b7a8c9e3427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4fSckXMnsuW"
      },
      "source": [
        "# Loca data from Google Drieve\n",
        "TRAIN_DATA_URL = \"/content/drive/My Drive/DS_data/ISEAR_train.csv\"\n",
        "TEST_DATA_URL = \"/content/drive/My Drive/DS_data/ISEAR_test.csv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(TRAIN_DATA_URL, TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(TRAIN_DATA_URL, TEST_DATA_URL)\n",
        "\n",
        "LABEL_COLUMN = \"emotion\"\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEmnOCoatpu-"
      },
      "source": [
        "def get_dataset(file_path):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=12, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True)\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unVB4cl9uF_q",
        "outputId": "050c3429-4ff8-4c10-c9d8-b4543e6e4e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "examples, labels = next(iter(raw_train_data)) # Just the first batch.\n",
        "print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
        "print(\"LABELS: \\n\", labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EXAMPLES: \n",
            " OrderedDict([('text', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
            "array([b'When I received my TE Score and my acceptance from University - \\xc3\\xa1 it had been a goal since I left the bank a year earlier.',\n",
            "       b'During lunch with some classmates, a priest was also there.  He \\xc3\\xa1 was eating desperately as if someone was going to take his plate \\xc3\\xa1 away.  He did it with gluttony.  He wiped his hands on his suit \\xc3\\xa1 several times and it was full of crumbs.',\n",
            "       b'When I was young, one day in the car we fell sick and ended up \\xc3\\xa1 vomitting on each other.',\n",
            "       b'When the gear broke on my car.',\n",
            "       b'On boat trip - saw mother giving young child (aprox 6-7 years) \\xc3\\xa1 cigarettes.',\n",
            "       b'One night I had a feeling that somebody was stealing my car, \\xc3\\xa1 but I was too frightened to go and see.',\n",
            "       b'I felt afraid when I smoked maryhuana for the first time in my \\xc3\\xa1 life with a lot of friends in the middle of the street at day \\xc3\\xa1 brake.',\n",
            "       b'When I saw that I had passed the university entrance exam.  It \\xc3\\xa1 made me forget all my problems.',\n",
            "       b\"I spoke with a friend on the phone who I haven't seen in many \\xc3\\xa1 years. It was a joyful event to talk to him.\",\n",
            "       b'Walking along with a dog barking at you and following you.',\n",
            "       b'There was an earthquake for several minutes and I was on the \\xc3\\xa1 eight floor.',\n",
            "       b\"Attending to a demand made by a client (I work in a bank) I \\xc3\\xa1 suggested her an application of money in a week ahead, but I \\xc3\\xa1 informed her wrongly. The client arrived a week after and the \\xc3\\xa1 application wasn't made and she lost with this a lot of time and \\xc3\\xa1 money.\"],\n",
            "      dtype=object)>)]) \n",
            "\n",
            "LABELS: \n",
            " tf.Tensor(\n",
            "[b'joy' b'disgust' b'disgust' b'sadness' b'disgust' b'fear' b'fear' b'joy'\n",
            " b'joy' b'fear' b'fear' b'guilt'], shape=(12,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPHyAevFv3C1"
      },
      "source": [
        "## Sklearn import data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwzaemQLv1cB"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DS_data/ISEAR_clean.csv\", sep=\",\")\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "labels = df.emotion.factorize()\n",
        "labels_index = labels[1]\n",
        "df['emotion'] = labels[0]\n",
        "\n",
        "training_data, testing_data, y_train, y_test = train_test_split(df.text, df.emotion, test_size=0.3, random_state=123, shuffle=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyF1OjoVzyt5",
        "outputId": "e2e3fc73-8450-4ce6-a095-ac757f353ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_data.head(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4102                When I had an argument with a friend.\n",
              "2284    One night, when I got out from the University ...\n",
              "2061    My father died last year after an 8-week sever...\n",
              "1998    The loss of my father as he died of a massive ...\n",
              "1261    The breaking up of a relationship.  We decided...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y8CFJhx2Suf",
        "outputId": "16646666-f0e1-4f8a-dc8a-97b882c1456f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y_train.head(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4102    3\n",
              "2284    1\n",
              "2061    3\n",
              "1998    3\n",
              "1261    3\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuMSCRm8ubXT"
      },
      "source": [
        "## Pre-processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJqaAE1ufG3",
        "outputId": "8633292c-4841-41fa-b8fc-2a6a304ef9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# extract features\n",
        "vectorizer1 = TfidfVectorizer(stop_words = \"english\")\n",
        "x_train = vectorizer1.fit_transform(training_data)\n",
        "# Use training data's vocabulary to create test tf-idf matrix\n",
        "vectorizer2 = TfidfVectorizer(stop_words = \"english\",vocabulary=vectorizer1.vocabulary_)\n",
        "x_test = vectorizer2.fit_transform(testing_data)\n",
        "\n",
        "vocab_size = x_train.shape[1]\n",
        "review_length = 500\n",
        "\n",
        "print(\"vocab_size : {}\".format(vocab_size))\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size : 7307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jONFmMXrvFjO"
      },
      "source": [
        "## Create and build LSTM Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pibIcL87vGqg",
        "outputId": "5b439d9f-409f-4e83-b15c-7925a3edd617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# We begin by defining the a empty stack. We'll use this for building our \n",
        "# network, later by layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
        "# individual words in our training set. Words close to one another share context \n",
        "# and or meaning. This spatial mapping is learning during the training process.\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout layers fight overfitting and forces the model to learn multiple \n",
        "# representations of the same data by randomly disabling neurons in the \n",
        "# learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# We are using a fast version of LSTM whih is optimised for GPUs. This layer \n",
        "# looks at the sequence of words in the review, along with their word embeddings\n",
        "# and uses both of these to determine to sentiment of a given review.\n",
        "model.add(\n",
        "    tf.compat.v1.keras.layers.CuDNNLSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
        "# activation function determines the output from this node - a value \n",
        "# between 0 and 1. Closer to 0 indicates a negative review. Closer to 1 \n",
        "# indicates a positive review.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           233824    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 32)                8448      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 242,305\n",
            "Trainable params: 242,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvD185R-2_LZ",
        "outputId": "a2ae6ccc-4e48-4a86-fd12-c3f3a643a3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x_train = np.array(x_train)\n",
        "#y_train = np.array(y_train)\n",
        "type(x_train)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBdg9IN56EHY",
        "outputId": "65e126f3-cead-4ebd-d636-8329b3a075aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC51lNHPwTcV"
      },
      "source": [
        "## Train the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIn2JdwGwW0t",
        "outputId": "194331b3-1788-464e-ba94-52bb7b6d6dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    x_train.toarray(), y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=256, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=2, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ") "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "17/17 [==============================] - 17s 996ms/step - loss: -0.6164 - accuracy: 0.1412 - val_loss: -3.4424 - val_accuracy: 0.1583\n",
            "Epoch 2/5\n",
            "17/17 [==============================] - 6s 380ms/step - loss: -6.4384 - accuracy: 0.1421 - val_loss: -8.6116 - val_accuracy: 0.1583\n",
            "Epoch 3/5\n",
            "17/17 [==============================] - 6s 381ms/step - loss: -10.5696 - accuracy: 0.1421 - val_loss: -11.9553 - val_accuracy: 0.1583\n",
            "Epoch 4/5\n",
            "17/17 [==============================] - 6s 378ms/step - loss: -13.8262 - accuracy: 0.1421 - val_loss: -14.9559 - val_accuracy: 0.1583\n",
            "Epoch 5/5\n",
            "17/17 [==============================] - 6s 378ms/step - loss: -16.6877 - accuracy: 0.1421 - val_loss: -17.3471 - val_accuracy: 0.1583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XqscrAg6fPF",
        "outputId": "457ae646-9e18-4cea-9c71-53be5c245e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted_classes = model.predict_classes(x_test.toarray())\n",
        "print(classification_report(y_test, predicted_classes, target_names=labels_index))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         joy       0.00      0.00      0.00       322\n",
            "        fear       0.14      1.00      0.24       315\n",
            "       anger       0.00      0.00      0.00       337\n",
            "     sadness       0.00      0.00      0.00       310\n",
            "     disgust       0.00      0.00      0.00       339\n",
            "       shame       0.00      0.00      0.00       338\n",
            "       guilt       0.00      0.00      0.00       339\n",
            "\n",
            "    accuracy                           0.14      2300\n",
            "   macro avg       0.02      0.14      0.03      2300\n",
            "weighted avg       0.02      0.14      0.03      2300\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T___U27_68nl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}